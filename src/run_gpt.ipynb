{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import read_data, read_env\n",
    "import os\n",
    "\n",
    "ENV_PATH = os.getcwd()[:-3]\n",
    "DATA_PATH = os.getcwd()[:-3] + \"/data\"\n",
    "\n",
    "env_vars = read_env(ENV_PATH)\n",
    "df = read_data(DATA_PATH)\n",
    "\n",
    "GPT_API_KEY = env_vars[\"GPT_API_KEY\"]\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Filter out empty rows\n",
    "df = df.dropna(subset=[\"Labelling\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "At ING Netherlands, customers can access a range of financial services. These services include savings and investments, personal banking, business banking, loans, insurance, and financial planning. ING Netherlands also offers online and mobile banking services, as well as a range of digital products and services.\n"
     ]
    }
   ],
   "source": [
    "# from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "# def generate_response(input_text):\n",
    "#   llm = OpenAI(temperature=0.7, openai_api_key=GPT_API_KEY)\n",
    "#   return llm(input_text)\n",
    "\n",
    "# print(generate_response(\"what happens at ING netherlands?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from rouge import Rouge\n",
    "\n",
    "\n",
    "def get_response(summary_entry):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a helpful assistant that provides concise summary of about 4 to 6 sentences. No other fluff is added to your response.\"),\n",
    "        HumanMessage(content=summary_entry)\n",
    "    ]\n",
    "    chat = ChatOpenAI(temperature=0, openai_api_key=GPT_API_KEY)\n",
    "\n",
    "    return chat(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised APIError: HTTP code 502 from API (<html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>cloudflare</center>\n",
      "</body>\n",
      "</html>\n",
      ").\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "ai = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Initialize the Rouge object\n",
    "    rouge = Rouge()\n",
    "\n",
    "    # Get summaries\n",
    "    ai_summary = get_response(row['item_1_short'])\n",
    "    human_summary = row['Labelling']\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    score = rouge.get_scores(ai_summary, human_summary)\n",
    "    scores.append(score[0]['rouge-l']['f'])\n",
    "    ai.append(ai_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"ai_summary\"] = ai\n",
    "df[\"scores\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4339274815685243"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "\n",
    "response = get_embedding(input=\"I am Reinier, I'm from Hillegom\", engine=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
