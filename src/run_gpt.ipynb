{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import read_data, read_env\n",
    "import os\n",
    "\n",
    "ENV_PATH = os.getcwd()[:-3]\n",
    "DATA_PATH = os.getcwd()[:-3] + \"/data\"\n",
    "\n",
    "env_vars = read_env(ENV_PATH)\n",
    "df = read_data(DATA_PATH)\n",
    "\n",
    "GPT_API_KEY = env_vars[\"GPT_API_KEY\"]\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Filter out empty rows\n",
    "df = df.dropna(subset=[\"Labelling\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "def get_response(summary_entry):\n",
    "    messages = [\n",
    "        # SystemMessage(content=\"You are a helpful assistant that provides concise summary of about 4 to 6 sentences. No other fluff is added to your response.\"),\n",
    "        # SystemMessage(content=\"You are a corporate lending specialist that provides concise summary of about 4 to 6 sentences. No other fluff is added to your response.\"),\n",
    "        SystemMessage(content=\"You are a helpful assistant that provides a short summary of the companies overview. No other unnecessary information is added to your response.\"),\n",
    "        HumanMessage(content=summary_entry)\n",
    "    ]\n",
    "    chat = ChatOpenAI(temperature=0, openai_api_key=GPT_API_KEY)\n",
    "\n",
    "    return chat(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 93376d21e17b649029d592c2f350f8ed in your message.).\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2e14bc659d7e0b225d928fa08b1f2597 in your message.).\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "scores = []\n",
    "ai = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # Initialize the Rouge object\n",
    "    rouge = Rouge()\n",
    "\n",
    "    # Get summaries\n",
    "    ai_summary = get_response(row['item_1_short'])\n",
    "    human_summary = row['Labelling']\n",
    "\n",
    "    # Compute ROUGE scores\n",
    "    score = rouge.get_scores(ai_summary, human_summary)\n",
    "    scores.append(score[0]['rouge-l']['f'])\n",
    "    ai.append(ai_summary)\n",
    "\n",
    "df[\"ai_summary\"] = ai\n",
    "df[\"scores\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4429880599172102"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "\n",
    "cosine_score = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    human_summary = get_embedding(text=row[\"Labelling\"], engine=\"text-embedding-ada-002\")\n",
    "    ai_summary = get_embedding(text=row[\"ai_summary\"], engine=\"text-embedding-ada-002\")\n",
    "\n",
    "    cosine_score.append(cosine_similarity(human_summary, ai_summary))\n",
    "\n",
    "df[\"cosine_score\"] = cosine_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9549998441238644"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cosine_score) / len(cosine_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('results_improved_prompt_3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
